{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72b20b95",
   "metadata": {},
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5309f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score, precision_score, recall_score\n",
    "import joblib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f09f36e",
   "metadata": {},
   "source": [
    "# === 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efc87e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_clean_text(text):\n",
    "    text = text.lower()\n",
    "    \n",
    "    # –£–¥–∞–ª–µ–Ω–∏–µ email –∞–¥—Ä–µ—Å–æ–≤\n",
    "    text = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', ' ', text)\n",
    "    # –£–¥–∞–ª–µ–Ω–∏–µ URL\n",
    "    text = re.sub(r'http\\S+|www\\.\\S+', ' ', text)\n",
    "    # –£–¥–∞–ª–µ–Ω–∏–µ —Ç–µ–ª–µ—Ñ–æ–Ω–Ω—ã—Ö –Ω–æ–º–µ—Ä–æ–≤\n",
    "    text = re.sub(r'\\b\\d{10,}\\b', ' ', text)\n",
    "    # –£–¥–∞–ª–µ–Ω–∏–µ –¥–µ–Ω–µ–∂–Ω—ã—Ö —Å—É–º–º (–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å–∏–º–≤–æ–ª –≤–∞–ª—é—Ç—ã –∫–∞–∫ –ø—Ä–∏–∑–Ω–∞–∫ —Å–ø–∞–º–∞)\n",
    "    text = re.sub(r'\\$\\d+', ' money ', text)\n",
    "    # –£–¥–∞–ª–µ–Ω–∏–µ –æ–±—ã—á–Ω—ã—Ö —á–∏—Å–µ–ª\n",
    "    text = re.sub(r'\\b\\d+\\b', ' ', text)\n",
    "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–æ—Å–∫–ª–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –∑–Ω–∞–∫–∏ (–ø—Ä–∏–∑–Ω–∞–∫ —Å–ø–∞–º–∞)\n",
    "    text = re.sub(r'!+', ' excl ', text)\n",
    "    # –£–¥–∞–ª–µ–Ω–∏–µ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏ (–∫—Ä–æ–º–µ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤)\n",
    "    text = re.sub(r'[^\\w\\s!?]', ' ', text)\n",
    "    # –£–¥–∞–ª–µ–Ω–∏–µ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9be15f",
   "metadata": {},
   "source": [
    "# === 2. –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6ffd0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...\n",
      "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤:\n",
      "label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n",
      "–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞...\n"
     ]
    }
   ],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "print(\"–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...\")\n",
    "data = pd.read_csv(\"spam.csv\", encoding=\"latin-1\")\n",
    "data = data[['v1', 'v2']]\n",
    "data.columns = ['label', 'message']\n",
    "\n",
    "print(\"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤:\")\n",
    "print(data['label'].value_counts())\n",
    "\n",
    "data['label'] = data['label'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "# –ü—Ä–∏–º–µ–Ω—è–µ–º —É–ª—É—á—à–µ–Ω–Ω—É—é –æ—á–∏—Å—Ç–∫—É\n",
    "print(\"–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞...\")\n",
    "data['cleaned_message'] = data['message'].apply(advanced_clean_text)\n",
    "\n",
    "# –£–¥–∞–ª—è–µ–º —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è\n",
    "data['message_length'] = data['cleaned_message'].apply(len)\n",
    "data = data[data['message_length'] > 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2752561",
   "metadata": {},
   "source": [
    "# –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41b76452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "–†–∞–∑–º–µ—Ä —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏: 4436\n",
      "–†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏: 1109\n"
     ]
    }
   ],
   "source": [
    "X = data['cleaned_message']\n",
    "y = data['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"\\n–†–∞–∑–º–µ—Ä —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏: {len(X_train)}\")\n",
    "print(f\"–†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1282021c",
   "metadata": {},
   "source": [
    "# === –û–±—É—á–µ–Ω–∏–µ ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bc1fc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "–ü–æ–∏—Å–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ KNN...\n"
     ]
    }
   ],
   "source": [
    "# –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –ª—É—á—à–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è KNN\n",
    "print(\"\\n–ü–æ–∏—Å–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ KNN...\")\n",
    "\n",
    "knn_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è —Å–µ—Ç–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "param_grid = {\n",
    "    'tfidf__max_features': [3000, 5000, 8000, 10000],\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'tfidf__min_df': [1, 2, 3],\n",
    "    'tfidf__max_df': [0.7, 0.8, 0.9],\n",
    "    'tfidf__stop_words': [None, 'english'],\n",
    "    'tfidf__sublinear_tf': [True, False],\n",
    "    'knn__n_neighbors': [3, 5, 7, 9, 11, 15],\n",
    "    'knn__metric': ['cosine', 'euclidean', 'manhattan', 'minkowski'],\n",
    "    'knn__weights': ['uniform', 'distance'],\n",
    "    'knn__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cd505e",
   "metadata": {},
   "source": [
    "# === 5. –û–±—É—á–µ–Ω–∏–µ k-NN ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3f6811d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞–π–¥–µ–Ω—ã!\n",
      "–õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
      "  tfidf__sublinear_tf: False\n",
      "  tfidf__stop_words: None\n",
      "  tfidf__ngram_range: (1, 1)\n",
      "  tfidf__min_df: 2\n",
      "  tfidf__max_features: 5000\n",
      "  tfidf__max_df: 0.9\n",
      "  knn__weights: distance\n",
      "  knn__n_neighbors: 3\n",
      "  knn__metric: cosine\n",
      "  knn__algorithm: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tybfist\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: FitFailedWarning: \n",
      "18 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\tybfist\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tybfist\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\tybfist\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tybfist\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\tybfist\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 239, in fit\n",
      "    return self._fit(X, y)\n",
      "           ~~~~~~~~~^^^^^^\n",
      "  File \"c:\\Users\\tybfist\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 534, in _fit\n",
      "    self._check_algorithm_metric()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\tybfist\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 455, in _check_algorithm_metric\n",
      "    raise ValueError(\n",
      "    ...<4 lines>...\n",
      "    )\n",
      "ValueError: Metric 'cosine' not valid. Use sorted(sklearn.neighbors.VALID_METRICS['kd_tree']) to get valid options. Metric can also be a callable function.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\tybfist\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tybfist\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\tybfist\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tybfist\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\tybfist\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 239, in fit\n",
      "    return self._fit(X, y)\n",
      "           ~~~~~~~~~^^^^^^\n",
      "  File \"c:\\Users\\tybfist\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 534, in _fit\n",
      "    self._check_algorithm_metric()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\tybfist\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 455, in _check_algorithm_metric\n",
      "    raise ValueError(\n",
      "    ...<4 lines>...\n",
      "    )\n",
      "ValueError: Metric 'cosine' not valid. Use sorted(sklearn.neighbors.VALID_METRICS['ball_tree']) to get valid options. Metric can also be a callable function.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\tybfist\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [0.60196148 0.90184896 0.00333333 0.00333333 0.88437066 0.03596523\n",
      " 0.35434672        nan 0.56040622 0.67393664 0.49890299 0.88391529\n",
      " 0.8763196  0.92085667 0.10112873 0.86372055 0.86874491 0.68429358\n",
      " 0.54580652 0.         0.87801973 0.80955198        nan 0.15108779\n",
      " 0.76057569 0.27405896 0.88733204 0.         0.54181337 0.00333333\n",
      " 0.71817792 0.00333333 0.00665008 0.71764703 0.84973054        nan\n",
      " 0.53550265 0.01328358 0.35081813 0.00333333        nan 0.00333333\n",
      "        nan 0.89174293        nan 0.33979934 0.63199085 0.80007078\n",
      " 0.00333333 0.89663274]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# –ò—Å–ø–æ–ª—å–∑—É–µ–º RandomizedSearchCV –¥–ª—è –±–æ–ª–µ–µ –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "knn_search = RandomizedSearchCV(\n",
    "    knn_pipeline, \n",
    "    param_grid, \n",
    "    n_iter=50,  # –ü—Ä–æ–≤–µ—Ä—è–µ–º 50 —Å–ª—É—á–∞–π–Ω—ã—Ö –∫–æ–º–±–∏–Ω–∞—Ü–∏–π\n",
    "    cv=3, \n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "knn_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"–õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞–π–¥–µ–Ω—ã!\")\n",
    "print(\"–õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:\")\n",
    "for param, value in knn_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42245cf1",
   "metadata": {},
   "source": [
    "# === –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e84a61ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "–§–ò–ù–ê–õ–¨–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´ KNN\n",
      "============================================================\n",
      "Accuracy: 0.9793\n",
      "Precision: 0.9846\n",
      "Recall: 0.8591\n",
      "F1-score: 0.9176\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       960\n",
      "           1       0.98      0.86      0.92       149\n",
      "\n",
      "    accuracy                           0.98      1109\n",
      "   macro avg       0.98      0.93      0.95      1109\n",
      "weighted avg       0.98      0.98      0.98      1109\n",
      "\n",
      "\n",
      "–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫:\n",
      "[[958   2]\n",
      " [ 21 128]]\n"
     ]
    }
   ],
   "source": [
    "# –û–±—É—á–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ —Å –ª—É—á—à–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏\n",
    "final_knn = knn_search.best_estimator_\n",
    "\n",
    "# –î–µ—Ç–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞\n",
    "y_pred = final_knn.predict(X_test)\n",
    "y_pred_proba = final_knn.predict_proba(X_test)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"–§–ò–ù–ê–õ–¨–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´ KNN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
    "print(f\"F1-score: {f1_score(y_test, y_pred):.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\n–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddab258f",
   "metadata": {},
   "source": [
    "# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä–∞ –æ—Ç–¥–µ–ª—å–Ω–æ (–¥–ª—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –æ—Ç–¥–µ–ª—å–Ω–æ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2cd72a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "–ê–Ω–∞–ª–∏–∑ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π:\n",
      "–°—Ä–µ–¥–Ω—è—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Å–ø–∞–º–∞ –¥–ª—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ —Å–ø–∞–º–∞: 0.849\n",
      "–°—Ä–µ–¥–Ω—è—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Å–ø–∞–º–∞ –¥–ª—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ –Ω–µ-—Å–ø–∞–º–∞: 0.009\n"
     ]
    }
   ],
   "source": [
    "# –ê–Ω–∞–ª–∏–∑ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è –º–æ–¥–µ–ª–∏\n",
    "print(\"\\n–ê–Ω–∞–ª–∏–∑ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π:\")\n",
    "spam_probs = y_pred_proba[y_test == 1, 1]  # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ —Å–ø–∞–º–∞\n",
    "ham_probs = y_pred_proba[y_test == 0, 1]   # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ –Ω–µ-—Å–ø–∞–º–∞\n",
    "\n",
    "print(f\"–°—Ä–µ–¥–Ω—è—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Å–ø–∞–º–∞ –¥–ª—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ —Å–ø–∞–º–∞: {spam_probs.mean():.3f}\")\n",
    "print(f\"–°—Ä–µ–¥–Ω—è—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Å–ø–∞–º–∞ –¥–ª—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ –Ω–µ-—Å–ø–∞–º–∞: {ham_probs.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d78236d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∫–∞–∫ 'improved_knn_spam_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "joblib.dump(final_knn, 'improved_knn_spam_model.pkl')\n",
    "print(\"\\n–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∫–∞–∫ 'improved_knn_spam_model.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "102f41f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π\n",
    "def analyze_message(model, message):\n",
    "    cleaned = advanced_clean_text(message)\n",
    "    prediction = model.predict([cleaned])[0]\n",
    "    probability = model.predict_proba([cleaned])[0]\n",
    "    \n",
    "    return {\n",
    "        'original': message,\n",
    "        'cleaned': cleaned,\n",
    "        'prediction': 'SPAM' if prediction == 1 else 'HAM',\n",
    "        'spam_probability': probability[1],\n",
    "        'ham_probability': probability[0]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8121b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "–¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ù–ê –ü–†–ò–ú–ï–†–ê–•\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–∞—Ö\n",
    "\n",
    "test_messages = [\n",
    "    \"Congratulations! You won $1000 prize! Call now to claim!!!\",\n",
    "    \"Hey, are we still meeting for lunch tomorrow?\",\n",
    "    \"URGENT: Your bank account needs verification. Click here.\",\n",
    "    \"Hi mom, I'll be home late today. See you for dinner\",\n",
    "    \"FREE iPhone waiting for you! Claim your prize now!\",\n",
    "    \"Meeting rescheduled to 3 PM. Please confirm attendance.\",\n",
    "    \"WINNER!! You have been selected for a free gift!\",\n",
    "    \"Can you pick up milk on your way home?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e92ebc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "–°–æ–æ–±—â–µ–Ω–∏–µ: Congratulations! You won $1000 prize! Call now to claim!!!\n",
      "–û—á–∏—â–µ–Ω–Ω–æ–µ: congratulations excl you won money prize excl call now to claim excl\n",
      "–†–µ–∑—É–ª—å—Ç–∞—Ç: SPAM (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Å–ø–∞–º–∞: 0.659)\n",
      "\n",
      "–°–æ–æ–±—â–µ–Ω–∏–µ: Hey, are we still meeting for lunch tomorrow?\n",
      "–û—á–∏—â–µ–Ω–Ω–æ–µ: hey are we still meeting for lunch tomorrow?\n",
      "–†–µ–∑—É–ª—å—Ç–∞—Ç: HAM (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Å–ø–∞–º–∞: 0.000)\n",
      "\n",
      "–°–æ–æ–±—â–µ–Ω–∏–µ: URGENT: Your bank account needs verification. Click here.\n",
      "–û—á–∏—â–µ–Ω–Ω–æ–µ: urgent your bank account needs verification click here\n",
      "–†–µ–∑—É–ª—å—Ç–∞—Ç: HAM (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Å–ø–∞–º–∞: 0.327)\n",
      "\n",
      "–°–æ–æ–±—â–µ–Ω–∏–µ: Hi mom, I'll be home late today. See you for dinner\n",
      "–û—á–∏—â–µ–Ω–Ω–æ–µ: hi mom i ll be home late today see you for dinner\n",
      "–†–µ–∑—É–ª—å—Ç–∞—Ç: HAM (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Å–ø–∞–º–∞: 0.000)\n",
      "\n",
      "–°–æ–æ–±—â–µ–Ω–∏–µ: FREE iPhone waiting for you! Claim your prize now!\n",
      "–û—á–∏—â–µ–Ω–Ω–æ–µ: free iphone waiting for you excl claim your prize now excl\n",
      "–†–µ–∑—É–ª—å—Ç–∞—Ç: HAM (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Å–ø–∞–º–∞: 0.319)\n",
      "\n",
      "–°–æ–æ–±—â–µ–Ω–∏–µ: Meeting rescheduled to 3 PM. Please confirm attendance.\n",
      "–û—á–∏—â–µ–Ω–Ω–æ–µ: meeting rescheduled to pm please confirm attendance\n",
      "–†–µ–∑—É–ª—å—Ç–∞—Ç: HAM (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Å–ø–∞–º–∞: 0.000)\n",
      "\n",
      "–°–æ–æ–±—â–µ–Ω–∏–µ: WINNER!! You have been selected for a free gift!\n",
      "–û—á–∏—â–µ–Ω–Ω–æ–µ: winner excl you have been selected for a free gift excl\n",
      "–†–µ–∑—É–ª—å—Ç–∞—Ç: HAM (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Å–ø–∞–º–∞: 0.331)\n",
      "\n",
      "–°–æ–æ–±—â–µ–Ω–∏–µ: Can you pick up milk on your way home?\n",
      "–û—á–∏—â–µ–Ω–Ω–æ–µ: can you pick up milk on your way home?\n",
      "–†–µ–∑—É–ª—å—Ç–∞—Ç: HAM (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Å–ø–∞–º–∞: 0.000)\n"
     ]
    }
   ],
   "source": [
    "for msg in test_messages:\n",
    "    result = analyze_message(final_knn, msg)\n",
    "    print(f\"\\n–°–æ–æ–±—â–µ–Ω–∏–µ: {result['original']}\")\n",
    "    print(f\"–û—á–∏—â–µ–Ω–Ω–æ–µ: {result['cleaned']}\")\n",
    "    print(f\"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result['prediction']} (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Å–ø–∞–º–∞: {result['spam_probability']:.3f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2133a529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "–ò–ù–¢–ï–†–ê–ö–¢–ò–í–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê\n",
      "–í–≤–µ–¥–∏—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ (–∏–ª–∏ 'quit' –¥–ª—è –≤—ã—Ö–æ–¥–∞):\n",
      "‚úÖ –í–ï–†–û–Ø–¢–ù–û –ù–ï –°–ü–ê–ú (0.0%)\n",
      "üö´ –í–´–°–û–ö–ê–Ø –í–ï–†–û–Ø–¢–ù–û–°–¢–¨ –°–ü–ê–ú–ê (100.0%)\n",
      "‚úÖ –í–ï–†–û–Ø–¢–ù–û –ù–ï –°–ü–ê–ú (0.0%)\n"
     ]
    }
   ],
   "source": [
    "# –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º –ø—Ä–æ–≤–µ—Ä–∫–∏\n",
    "def interactive_check():\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"–ò–ù–¢–ï–†–ê–ö–¢–ò–í–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê\")\n",
    "    print(\"–í–≤–µ–¥–∏—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ (–∏–ª–∏ 'quit' –¥–ª—è –≤—ã—Ö–æ–¥–∞):\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"\\n–°–æ–æ–±—â–µ–Ω–∏–µ: \")\n",
    "        if user_input.lower() == 'quit':\n",
    "            break\n",
    "            \n",
    "        if user_input.strip():\n",
    "            result = analyze_message(final_knn, user_input)\n",
    "            prob = result['spam_probability']\n",
    "            \n",
    "            if prob > 0.7:\n",
    "                print(f\"üö´ –í–´–°–û–ö–ê–Ø –í–ï–†–û–Ø–¢–ù–û–°–¢–¨ –°–ü–ê–ú–ê ({prob:.1%})\")\n",
    "            elif prob > 0.3:\n",
    "                print(f\"‚ö†Ô∏è  –í–û–ó–ú–û–ñ–ù–û –°–ü–ê–ú ({prob:.1%})\")\n",
    "            else:\n",
    "                print(f\"‚úÖ –í–ï–†–û–Ø–¢–ù–û –ù–ï –°–ü–ê–ú ({prob:.1%})\")\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏\n",
    "interactive_check()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
